{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1246711,"sourceType":"datasetVersion","datasetId":710024},{"sourceId":1435063,"sourceType":"datasetVersion","datasetId":840719}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mohamedelhawary0/face-mask-detection?scriptVersionId=170504826\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Python libraries that we need for this task","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport random\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\n# from keras.preprocessing.image import ImageDataGenerator\n# from keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndirectory = \"../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\"\nimage_directory = \"../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\"\ndf = pd.read_csv(\"../input/face-mask-detection-dataset/train.csv\")\ndf_test = pd.read_csv(\"../input/face-mask-detection-dataset/submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:33:20.507899Z","iopub.execute_input":"2024-02-29T21:33:20.508311Z","iopub.status.idle":"2024-02-29T21:33:35.472454Z","shell.execute_reply.started":"2024-02-29T21:33:20.508279Z","shell.execute_reply":"2024-02-29T21:33:35.471296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Helper Functions","metadata":{}},{"cell_type":"code","source":"# cvNet = cv2.dnn.readNetFromCaffe('weights.caffemodel')\n\ndef getJSON(filePathandName):\n    with open(filePathandName,'r') as f:\n        return json.load(f)\n    \ndef adjust_gamma(image, gamma=1.0):\n    invGamma = 1.0 / gamma\n    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)])\n    return cv2.LUT(image.astype(np.uint8), table.astype(np.uint8))    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:33:43.928736Z","iopub.execute_input":"2024-02-29T21:33:43.929422Z","iopub.status.idle":"2024-02-29T21:33:43.93649Z","shell.execute_reply.started":"2024-02-29T21:33:43.929392Z","shell.execute_reply":"2024-02-29T21:33:43.93519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Processing\nThe next step is now to explore the JSON data provided for the training:","metadata":{}},{"cell_type":"code","source":"jsonfiles= []\nfor i in os.listdir(directory):\n    jsonfiles.append(getJSON(os.path.join(directory,i)))\njsonfiles[0]","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:34:55.992918Z","iopub.execute_input":"2024-02-29T21:34:55.993291Z","iopub.status.idle":"2024-02-29T21:34:58.535891Z","shell.execute_reply.started":"2024-02-29T21:34:55.993265Z","shell.execute_reply":"2024-02-29T21:34:58.534644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Annotations field contains the data of all the faces present in a particular image.\nThere are different class names, but the real class names are face_with_mask and face_no_mask.","metadata":{}},{"cell_type":"code","source":"# df = pd.read_csv(\"train.csv\")\npd.read_csv(\"../input/face-mask-detection-dataset/train.csv\")\ndf.head(100)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:35:00.791271Z","iopub.execute_input":"2024-02-29T21:35:00.79183Z","iopub.status.idle":"2024-02-29T21:35:00.830677Z","shell.execute_reply.started":"2024-02-29T21:35:00.791792Z","shell.execute_reply":"2024-02-29T21:35:00.829575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the mask and the non_mask labels, the bounding box data of the json files is extracted. The faces of a particular image are extracted and stored in the data list with its tag for the learning process.","metadata":{}},{"cell_type":"code","source":"data = []\nimg_size = 124\nmask = ['face_with_mask']\nnon_mask = [\"face_no_mask\"]\nlabels={'mask':0,'without mask':1}\nfor i in df[\"name\"].unique():\n    f = i+\".json\"\n    for j in getJSON(os.path.join(directory,f)).get(\"Annotations\"):\n        if j[\"classname\"] in mask:\n            x,y,w,h = j[\"BoundingBox\"]\n            img = cv2.imread(os.path.join(image_directory,i),1)\n            img = img[y:h,x:w]\n            img = cv2.resize(img,(img_size,img_size))\n            data.append([img,labels[\"mask\"]])\n        if j[\"classname\"] in non_mask:\n            x,y,w,h = j[\"BoundingBox\"]\n            img = cv2.imread(os.path.join(image_directory,i),1)\n            img = img[y:h,x:w]\n            img = cv2.resize(img,(img_size,img_size))    \n            data.append([img,labels[\"without mask\"]])\nrandom.shuffle(data)        \n\np = []\nfor face in data:\n    if(face[1] == 0):\n        p.append(\"Mask\")\n    else:\n        p.append(\"No Mask\")\n# s = []\n# for face in data:\n#     if(face[1] == 0):\n#         p.append(0)\n#     else:\n#         p.append(1)\n# sns.countplot(s) ","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:36:36.788896Z","iopub.execute_input":"2024-02-29T21:36:36.789307Z","iopub.status.idle":"2024-02-29T21:38:14.009395Z","shell.execute_reply.started":"2024-02-29T21:36:36.789275Z","shell.execute_reply":"2024-02-29T21:38:14.008265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = []\nfor face in data:\n    if(face[1] == 0):\n        s.append(0)\n    else:\n        s.append(1)\nsns.countplot(s)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:38:18.921631Z","iopub.execute_input":"2024-02-29T21:38:18.921999Z","iopub.status.idle":"2024-02-29T21:38:19.182539Z","shell.execute_reply.started":"2024-02-29T21:38:18.92197Z","shell.execute_reply":"2024-02-29T21:38:19.181619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"reshape the data before training a neural network:","metadata":{}},{"cell_type":"code","source":"X = []\nY = []\nfor features,label in data:\n    X.append(features)\n    Y.append(label)\n\nX = np.array(X)/255.0\nX = X.reshape(-1,124,124,3)\nY = np.array(Y)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:38:23.367719Z","iopub.execute_input":"2024-02-29T21:38:23.36891Z","iopub.status.idle":"2024-02-29T21:38:24.136962Z","shell.execute_reply.started":"2024-02-29T21:38:23.368863Z","shell.execute_reply":"2024-02-29T21:38:24.136046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Neural Network for Face Mask Detection","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding = \"same\", activation='relu', input_shape=(124,124,3)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n \nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam' ,metrics=['accuracy'])\nxtrain,xval,ytrain,yval=train_test_split(X, Y,train_size=0.8,random_state=0)\ndatagen = ImageDataGenerator(featurewise_center=False,  samplewise_center=False,  \n                             featurewise_std_normalization=False,  \n                             samplewise_std_normalization=False,  \n                             zca_whitening=False,    \n                             rotation_range=15,    \n                             width_shift_range=0.1,\n                             height_shift_range=0.1,  \n                             horizontal_flip=True,  \n                             vertical_flip=False)\n\ndatagen.fit(xtrain)\n\n\n\nhistory = model.fit(datagen.flow(xtrain, ytrain, batch_size=32),\n                    steps_per_epoch=xtrain.shape[0]//32,\n                    epochs=50,\n                    verbose=1,\n                    validation_data=(xval, yval))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:38:26.26476Z","iopub.execute_input":"2024-02-29T21:38:26.265216Z","iopub.status.idle":"2024-02-29T21:46:24.12729Z","shell.execute_reply.started":"2024-02-29T21:38:26.265175Z","shell.execute_reply":"2024-02-29T21:46:24.126383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:46:30.046957Z","iopub.execute_input":"2024-02-29T21:46:30.047684Z","iopub.status.idle":"2024-02-29T21:46:30.08211Z","shell.execute_reply.started":"2024-02-29T21:46:30.047651Z","shell.execute_reply":"2024-02-29T21:46:30.080992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wc = '/kaggle/input/caffe-face-detector-opencv-pretrained-model/weights.caffemodel'\narchi = '/kaggle/input/caffe-face-detector-opencv-pretrained-model/architecture.txt'\ncvNet = cv2.dnn.readNetFromCaffe(archi, wc)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:46:32.237317Z","iopub.execute_input":"2024-02-29T21:46:32.238164Z","iopub.status.idle":"2024-02-29T21:46:32.461944Z","shell.execute_reply.started":"2024-02-29T21:46:32.238129Z","shell.execute_reply":"2024-02-29T21:46:32.460777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = ['1114.png','1504.jpg', '0072.jpg','0012.jpg','0353.jpg','1374.jpg']\n\ngamma = 2.0\nfig = plt.figure(figsize = (14,14))\nrows = 3\ncols = 2\naxes = []\nassign = {'0':'Mask','1':\"No Mask\"}\nfor j,im in enumerate(test_images):\n    image =  cv2.imread(os.path.join(image_directory,im),1)\n    image =  adjust_gamma(image, gamma=gamma)\n    (h, w) = image.shape[:2]\n    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300,300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n    cvNet.setInput(blob)\n    detections = cvNet.forward()\n    for i in range(0, detections.shape[2]):\n        try:\n            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n            (startX, startY, endX, endY) = box.astype(\"int\")\n            frame = image[startY:endY, startX:endX]\n            confidence = detections[0, 0, i, 2]\n            if confidence > 0.2:\n                im = cv2.resize(frame,(img_size,img_size))\n                im = np.array(im)/255.0\n                im = im.reshape(1,124,124,3)\n                result = model.predict(im)\n                if result>0.5:\n                    label_Y = 1\n                else:\n                    label_Y = 0\n                cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n                cv2.putText(image,assign[str(label_Y)] , (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (36,255,12), 2)\n        \n        except:pass\n    axes.append(fig.add_subplot(rows, cols, j+1))\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T21:46:33.547404Z","iopub.execute_input":"2024-02-29T21:46:33.548294Z","iopub.status.idle":"2024-02-29T21:46:38.184921Z","shell.execute_reply.started":"2024-02-29T21:46:33.548261Z","shell.execute_reply":"2024-02-29T21:46:38.180355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}